{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionResNetV2\n",
    "\n",
    "This Notebook trains an InceptionResNetV2 model with the Stanford Dogs dataset, pretrained on ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import json\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")\n",
    "import paths\n",
    "\n",
    "REPO_DIR = paths.get_repo_path()\n",
    "ROOT_DIR = REPO_DIR / \"models\"\n",
    "DATA_BASE_PATH = paths.get_data_path() / \"stanford-dogs-dataset\"\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "os.chdir(REPO_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_df_path = DATA_BASE_PATH / \"dogs_df.csv\"\n",
    "\n",
    "dogs_df = pd.read_csv(dogs_df_path)\n",
    "print(dogs_df.shape[0])\n",
    "dogs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ROOT_DIR / \"breeds_dict.json\", \"r\") as f:\n",
    "    breed_dict = json.load(f)\n",
    "len(breed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224\n",
    "\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "CLASS_NAMES = list(breed_dict.values())\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "# MODEL\n",
    "MODEL_PATH = REPO_DIR / \"models\"\n",
    "LOG_PATH = ROOT_DIR / \"log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data_df, val_data_df = train_test_split(\n",
    "                                    dogs_df, \n",
    "                                    test_size=VALIDATION_SPLIT,\n",
    "                                    stratify=dogs_df[\"breed\"],\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df_dublicated = pd.concat([train_data_df for _ in range(2)]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    \n",
    "    horizontal_flip=True,\n",
    "    # vertical_flip=True,\n",
    "    rotation_range=36,\n",
    "    \n",
    "    height_shift_range=0.1,       # No need to shift the image\n",
    "    width_shift_range=0.1,\n",
    "    zoom_range=0.15,\n",
    "    \n",
    "    shear_range=0.1,              # Seems to be useful\n",
    "    brightness_range = [0.75, 1.25],\n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_generator.flow_from_dataframe(\n",
    "    train_data_df_dublicated,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"breed\",\n",
    "    \n",
    "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_images = val_generator.flow_from_dataframe(\n",
    "    val_data_df,\n",
    "    x_col=\"image_path\",\n",
    "    y_col=\"breed\",\n",
    "    \n",
    "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    \n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_images = val_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 5\n",
    "num_cols = 5\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "images, labels = train_images.next()\n",
    "for i in range(num_cols * num_rows):\n",
    "    plt.subplot(num_cols, num_rows, i + 1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.title(CLASS_NAMES[labels[i].argmax()])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = train_images.next()[0][0].shape\n",
    "TRAIN_MODELS = True\n",
    "TRAIN_MODELS = False\n",
    "LEARNING_RATE = 20e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, log_loss\n",
    "\n",
    "def predict_label(images, model):\n",
    "    predictions = model.predict(images)\n",
    "    return predictions.argmax(axis=1)\n",
    "\n",
    "\n",
    "# ploting the model training history\n",
    "def plot_model_performance(history, figsize=(10, 10)):\n",
    "    preformance = {key: val for key, val in history.history.items() if \"loss\" not in key}\n",
    "    losses = {key: val for key, val in history.history.items() if \"loss\" in key}\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title('Model Performance')\n",
    "    for key, val in preformance.items():\n",
    "        plt.plot(val, label=key)\n",
    "    plt.legend(preformance.keys())\n",
    "    plt.xlabel('Epoch')\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title('Model Losses')\n",
    "    for key, val in losses.items():\n",
    "        plt.plot(val, label=key)\n",
    "    plt.legend(losses.keys())\n",
    "    plt.xlabel('Epoch')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def compute_performance_metrics(y, y_pred, verbose=1):\n",
    "    # labels = test_images_.y.argmax(axis=1)\n",
    "    labels = y\n",
    "    labels_cat = tf.keras.utils.to_categorical(labels, NUM_CLASSES)\n",
    "    # pred_cat = model.predict(test_images_)\n",
    "    pred_cat = y_pred\n",
    "    pred = pred_cat.argmax(axis=1)\n",
    "\n",
    "    performance_metrics = {}\n",
    "    performance_metrics[\"accuracy\"] = round(accuracy_score(labels, pred), 4)\n",
    "    performance_metrics[\"top_5_accuracy\"] = round(top_k_categorical_accuracy(labels_cat, pred_cat, k=5).numpy().sum() / len(y), 4)\n",
    "    performance_metrics[\"f1_score\"] = round(f1_score(labels, pred, average=\"macro\"), 4)\n",
    "    performance_metrics[\"precision\"] = round(precision_score(labels, pred, average=\"macro\"), 4)\n",
    "    performance_metrics[\"recall\"] = round(recall_score(labels, pred, average=\"macro\"), 4)\n",
    "    performance_metrics[\"loss\"] = round(log_loss(labels_cat, pred_cat), 4)\n",
    "    \n",
    "    performance_df.loc[model.name] = performance_metrics\n",
    "    if verbose:\n",
    "        return performance_df.loc[model.name]\n",
    "\n",
    "performance_df = pd.DataFrame(columns=[\"accuracy\", \"top_5_accuracy\", \"precision\", \"recall\", \"f1_score\", \"loss\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, GlobalAveragePooling2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_backbone(input_shape, num_classes):\n",
    "    model = InceptionResNetV2(include_top=False, weights=\"imagenet\", input_shape=input_shape)\n",
    "    model.trainable = False\n",
    "    return model\n",
    "\n",
    "model_backbone = get_model_backbone(input_shape=INPUT_SHAPE, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name=\"InceptionResNetV2\")\n",
    "model.add(model_backbone)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(NUM_CLASSES, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(\n",
    "        learning_rate=LEARNING_RATE\n",
    "        ), \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        'top_k_categorical_accuracy',\n",
    "        ]\n",
    "    )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint, CSVLogger\n",
    "\n",
    "monitor_metric = 'val_accuracy'\n",
    "learning_rate_decay_rate = 0.8\n",
    "def get_callbacks():\n",
    "    callbacks = {}\n",
    "    \n",
    "    callbacks[\"EarlyStopping\"] = EarlyStopping(\n",
    "            monitor=monitor_metric,\n",
    "            patience=5,\n",
    "            mode = \"auto\",\n",
    "            verbose=1,\n",
    "        )\n",
    "    \n",
    "    callbacks[\"LearningRateScheduler\"] = LearningRateScheduler(step_decay)\n",
    "\n",
    "    callbacks[\"ModelCheckpoint\"] = ModelCheckpoint(\n",
    "            MODEL_PATH / f\"{model.name}.h5\",\n",
    "            monitor=monitor_metric,\n",
    "            save_best_only=True,\n",
    "            mode='auto',\n",
    "            verbose=1,\n",
    "    )\n",
    "    \n",
    "    return callbacks\n",
    "\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lr = LEARNING_RATE\n",
    "    k = learning_rate_decay_rate\n",
    "    lr = initial_lr * np.exp(-k*epoch)\n",
    "    return lr\n",
    "\n",
    "callbacks = get_callbacks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "train_model = not (os.path.exists(MODEL_PATH / f\"{model.name}.h5\")) or TRAIN_MODELS\n",
    "steps = round(len(train_images) / 1.25)\n",
    "if train_model:\n",
    "    history = model.fit(train_images, \n",
    "                        validation_data=val_images,\n",
    "                        epochs=35,\n",
    "                        steps_per_epoch=steps,\n",
    "                        callbacks=callbacks,                        \n",
    "    )\n",
    "else:\n",
    "    model_path = MODEL_PATH / f\"{model.name}.h5\"\n",
    "    model = load_model(model_path)\n",
    "    print(f\"{model.name} model loaded from {model_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    model.evaluate(test_images)\n",
    "    plot_model_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shuffle = False\n",
    "test_labels = test_images.labels\n",
    "test_labels_pred_ohe = model.predict(test_images)\n",
    "test_labels_pred = test_labels_pred_ohe.argmax(axis=1)\n",
    "compute_performance_metrics(test_labels, test_labels_pred_ohe, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df.sort_values(by=\"accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "accuracy          0.8533\n",
    "top_5_accuracy    0.9818\n",
    "precision         0.8571\n",
    "recall            0.8522\n",
    "f1_score          0.8520\n",
    "loss              0.4987\n",
    "Name: InceptionResNetV2, dtype: float64\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env_tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5a1ae6899980971a482c9ba4350aa5d29248927543f8d54686f28fa951765f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
